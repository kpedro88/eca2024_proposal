As described in the introduction, the program of dark QCD searches described here relies
on collaboration facilitated by the LHC Physics Center at Fermilab.
This includes support from programs such as LPC Graduate Scholar, LPC Distinguished Researcher, and LPC Guest and Visitor,
which provide funds for university collaborators to spend time at Fermilab.

The necessary computing resources to conduct the searches are generally available from Fermilab,
which hosts a Tier 3 user analysis farm and a new elastic analysis facility~\cite{Savard:2023wwi,Benjamin:2022dpo,Flechas:2022uug},
and from the global CMS collaboration, which provides significant grid computing resources that can be accessed via the CMS Connect service hosted at the University of Chicago.
The new searches will continue to employ the columnar analysis techniques~\cite{Smith:2020pxs} already used in the current searches,
ensuring optimal use of the analysis facility resources.

The input data to train the diffusion and refinement algorithms, generated by running classical simulation engines,
will be centrally produced by the CMS collaboration, coordinated by the PI in his role as convener of the ML4Sim group.
The AI algorithms to tag SVJs and reconstruct dark hadron masses will be trained and tested on a combination of centrally processed data and simulation from the CMS collaboration
and additional samples produced with the Fermilab Tier 3 facility and CMS grid computing.
Training the algorithms will require dedicated resources, specifically state of the art GPUs.
Fermilab provides access to high-end Nvidia V100 and A100 GPUs through its institutional Wilson cluster and elastic analysis facility.

Deployment of the algorithm using inference as a service will be tested in cooperation with CMS computing sites that provide the requisite coprocessor resources,
as well as at participating HPC centers.
We will build on our existing collaborations with Purdue University and NERSC, among others.
